{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from sklearn.linear_model import Ridge\n",
    "import time\n",
    "import datetime\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk.data\n",
    "from nltk import wordpunct_tokenize\n",
    "import lda\n",
    "import lda.datasets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return a set of top words of length size \n",
    "def getVocab(reviews_u_b,size):\n",
    "    wordCounts = defaultdict(int)\n",
    "    punctuation = set(string.punctuation)\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = stopwords.words('english')\n",
    "    for user in reviews_u_b:\n",
    "        for business in reviews_u_b[user]:\n",
    "            r = ''.join([c for c in reviews_u_b[user][business].lower() if not c in punctuation])\n",
    "            for w in r.split():\n",
    "                if w in stops:\n",
    "                    continue\n",
    "    #             w = stemmer.stem(w)\n",
    "                wordCounts[w] += 1\n",
    "    counts = [(wordCounts[w], w) for w in wordCounts]\n",
    "    counts.sort()\n",
    "    counts.reverse()\n",
    "    words = [x[1] for x in counts[:size]]\n",
    "    sorted(words)\n",
    "    return words\n",
    "    \n",
    "    \n",
    "# helper that return vocab to index dict \n",
    "# each word is mapped to index from 0 to len(vocab)\n",
    "def getVocabToIndex(vocab):\n",
    "#     sorted(vocab)\n",
    "    index = 0\n",
    "    dict = {}\n",
    "    for word in vocab:\n",
    "        dict[word] = index\n",
    "        index += 1\n",
    "    return dict\n",
    "\n",
    "def getBusinessToIndex(reviews_b_u):\n",
    "    index = 0\n",
    "    dict = {}\n",
    "    for business in reviews_b_u:\n",
    "        dict[business] = index\n",
    "        index += 1\n",
    "    return dict\n",
    "    \n",
    "def getBusineesToVocabVector(reviews_b_u,vocab):\n",
    "    # return a dict \n",
    "    # key is business ID\n",
    "    # value is a vector of word counts of length equal to vocab\n",
    "    punctuation = set(string.punctuation)\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = stopwords.words('english')\n",
    "    bussiness_to_vvector = {}\n",
    "    vocab_index_dict = getVocabToIndex(vocab)\n",
    "    for business in reviews_b_u:\n",
    "        bussiness_to_vvector[business] = np.array([0]*len(vocab))\n",
    "        for user in reviews_b_u[business]:\n",
    "            r = ''.join([c for c in reviews_b_u[business][user].lower() if not c in punctuation])\n",
    "            for w in r.split():\n",
    "                if w in stops or w not in vocab_index_dict:\n",
    "                    continue\n",
    "    #             w = stemmer.stem(w)\n",
    "                bussiness_to_vvector[business][vocab_index_dict[w]] += 1\n",
    "    return bussiness_to_vvector\n",
    "            \n",
    "def getUserToVocabVector(reviews_u_b,vocab):\n",
    "    # return a dict \n",
    "    # key is user ID\n",
    "    # value is a vector of word counts of length equal to vocab  \n",
    "    punctuation = set(string.punctuation)\n",
    "    stemmer = PorterStemmer()\n",
    "    stops = stopwords.words('english')\n",
    "    user_to_vvector = {}\n",
    "    vocab_index_dict = getVocabToIndex(vocab)\n",
    "    for user in reviews_u_b:\n",
    "        user_to_vvector[user] = np.array([0]*len(vocab))\n",
    "        for business in reviews_u_b[user]:\n",
    "            r = ''.join([c for c in reviews_u_b[user][business].lower() if not c in punctuation])\n",
    "            for w in r.split():\n",
    "                if w in stops or w not in vocab_index_dict:\n",
    "                    continue\n",
    "    #             w = stemmer.stem(w)\n",
    "                user_to_vvector[user][vocab_index_dict[w]] += 1\n",
    "    return user_to_vvector\n",
    "    \n",
    "def trainLDA(reviews_b_u,vocab,num_topics,bussiness_to_vvector):\n",
    "    # build matrix for each business from getBusineesToVocabVector\n",
    "    # fit lda model \n",
    "    # return lda model\n",
    "    \n",
    "    business_to_index = getBusinessToIndex(reviews_b_u)\n",
    "    \n",
    "    # train vector X\n",
    "    X = np.zeros((len(reviews_b_u.keys()),len(vocab))).astype(np.intc)\n",
    "\n",
    "    for business in reviews_b_u:\n",
    "        index = business_to_index[business]\n",
    "        X[index] = (bussiness_to_vvector[business]).astype(np.intc)\n",
    "    \n",
    "\n",
    "    #define model\n",
    "    model = lda.LDA(n_topics=num_topics, n_iter=1500, random_state=1)\n",
    "    X.astype(np.intc)\n",
    "    print X\n",
    "    #fit model\n",
    "    model.fit(X)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def printTopWordsPerTopic(n,model):\n",
    "    # return a dict\n",
    "    # return top no words in each topic\n",
    "    topic_word = model.topic_word_\n",
    "    n_top_words = n\n",
    "    for i, topic_dist in enumerate(topic_word):\n",
    "        topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "        print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n",
    "    \n",
    "    \n",
    "def getTopicDist(X,model):\n",
    "    #given some vocab vector , predict top distribution\n",
    "    t = model.transform(X, max_iter=20, tol=1e-16)\n",
    "    return t\n",
    "\n",
    "def getTopTopics(X,model,num_top):\n",
    "    n_top_words = num_top\n",
    "    topic_word = model.topic_word_\n",
    "    num_topics = topic_word.shape[0]\n",
    "    vocab_size = topic_word.shape[1]\n",
    "    t = model.transform(X, max_iter=20, tol=1e-16)\n",
    "    for i in range(t.shape[0]):\n",
    "        topic_arr = np.array([a for a in range(num_topics)])\n",
    "        print \"shape:\",t.shape\n",
    "        print \"i:\",i\n",
    "        print \"dist:\",t[i]\n",
    "        print \"for index:\", i , \" the top topic indices:\",(topic_arr)[np.argsort(t[i])][:-(num_top+1):-1]\n",
    "        \n",
    "def getUserLDAFeatures(model, user_to_vvector):\n",
    "    #return dict of user to topic distribution\n",
    "    user_to_topic_dist = {}\n",
    "    for user in user_to_vvector:\n",
    "        user_to_topic_dist[user] = getTopicDist(user_to_vvector[user],model)\n",
    "    return user_to_topic_dist\n",
    "    \n",
    "def getBusinessLDAFeatures(model,business_to_vvector):\n",
    "    #return dict of business to topic distribution\n",
    "    business_to_topic_dist = {}\n",
    "    for business in business_to_vvector:\n",
    "        business_to_topic_dist[business] = getTopicDist(business_to_vvector[business],model)\n",
    "    return business_to_topic_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildRegressionFeatures(model,ratings_u_b,\n",
    "                            user_to_avg_rating,business_to_avg_rating,reviews_u_b,\n",
    "                            reviews_b_u,global_avg,vocab):\n",
    "    # retrun a matrix X\n",
    "    # every row in the matrix is a feature vector for a given user - business combination\n",
    "    # retrun a Y vector\n",
    "    # every row in the Y vector is the the rating that we need to predict for the  feature vector in the corresponding \n",
    "    # row of the X matrix\n",
    "    # return a dict that is a mapping of user -> business -> row number in the feature matrix\n",
    "    mapping = defaultdict(dict)\n",
    "    num_user_busi = 0\n",
    "    for user in reviews_u_b:\n",
    "        for buss in reviews_u_b[user]:\n",
    "            num_user_busi += 1\n",
    "            \n",
    "    topic_word = model.topic_word_\n",
    "    num_topics = topic_word.shape[0]\n",
    "    vocab_size = topic_word.shape[1]\n",
    "    \n",
    "    num_feats = num_topics + 3\n",
    "    X = np.zeros((num_user_busi,num_feats)) #  features from LDA + user_avg + item_avg + 1 offset\n",
    "    Y = np.zeros((num_user_busi,1)) # Ratings - labels\n",
    "    \n",
    "    user_to_vvector      = getUserToVocabVector(reviews_u_b,vocab)\n",
    "    bussiness_to_vvector = getBusineesToVocabVector(reviews_b_u,vocab)\n",
    "    \n",
    "    index = 0\n",
    "    for user in reviews_u_b:\n",
    "        user_topic_dist = getTopicDist(user_to_vvector[user],model)\n",
    "#         if sum(user_topic_dist[0]) != 1:\n",
    "#                 print \"sum not 1 for user_topic_dist[0]:\",user_topic_dist[0]\n",
    "#         print \"shape of user_topic_dist:\",user_topic_dist.shape\n",
    "        for buss in reviews_u_b[user]:\n",
    "            buss_topic_dist = getTopicDist(bussiness_to_vvector[buss],model)\n",
    "#             if sum(buss_topic_dist[0]) != 1:\n",
    "#                 print \"sum not 1 for buss_topic_dist[0]:\",buss_topic_dist[0]\n",
    "# #             print \"shape of buss_topic_dist:\",buss_topic_dist.shape\n",
    "            lda_feat = np.array([0.0]*num_feats)\n",
    "            for i in range(num_topics):\n",
    "#                 print \"i:\",i\n",
    "                lda_feat[i] = user_topic_dist[0][i] * buss_topic_dist[0][i]\n",
    "            if user in user_to_avg_rating:\n",
    "                lda_feat[num_topics] = user_to_avg_rating[user] \n",
    "            else:\n",
    "                lda_feat[num_topics] = global_avg \n",
    "            if buss in business_to_avg_rating:\n",
    "                lda_feat[num_topics+1] = business_to_avg_rating[buss]\n",
    "            else:\n",
    "                lda_feat[num_topics+1] = global_avg\n",
    "            lda_feat[num_topics + 2] = 1\n",
    "            X[index] = lda_feat\n",
    "            Y[index] = ratings_u_b[user][buss]\n",
    "            if Y[index] == 0:\n",
    "                print \"Y is 0\"\n",
    "            mapping[user][buss] = index\n",
    "            index += 1\n",
    "    return [X,Y,mapping,user_to_vvector,bussiness_to_vvector]\n",
    "\n",
    "def getGlobalAvg(reviews_u_b, ratings_u_b):\n",
    "    avg = 0.0\n",
    "    count = 0\n",
    "    for user in reviews_u_b:\n",
    "        for bussiness in reviews_u_b[user]:\n",
    "            avg += ratings_u_b[user][bussiness]\n",
    "            count += 1\n",
    "    return avg * 1.0 / count\n",
    "\n",
    "def getBaselineMSE(ratings_u_b,pred):\n",
    "    se = 0.0\n",
    "    count = 0\n",
    "    for user in ratings_u_b:\n",
    "        for business in ratings_u_b[user]:\n",
    "            se += pow((ratings_u_b[user][business] - pred),2)\n",
    "            count += 1\n",
    "    return se * 1.0 / count\n",
    "\n",
    "def getMSE(X,Y,theta):\n",
    "    se = 0.0 \n",
    "    for i in range(X.shape[0]):\n",
    "        pred = np.dot(X[i],theta)\n",
    "        se += pow((pred - Y[i]),2)\n",
    "    return se * 1.0 / X.shape[0]\n",
    "\n",
    "def getAvgVVector(xToVVector, num_topics):\n",
    "    avg_vec = np.array([0]*num_topics).astype(np.intc)\n",
    "    count = 0.0\n",
    "    for x in xToVVector:\n",
    "        for v in xToVVector[x]:\n",
    "            avg_vec += v\n",
    "            count += 1\n",
    "    print \"count:\",count\n",
    "    print \"before div avg_vec:\",avg_vec\n",
    "    avg_vec /= count\n",
    "    avg_vec.astype(np.intc)\n",
    "    print \"returning avg_vec:\", avg_vec\n",
    "    return avg_vec\n",
    "\n",
    "def build_test_reg_features(model,user_to_vvector,bussiness_to_vvector,\n",
    "            reviews_u_b,ratings_u_b,global_avg):\n",
    "    \n",
    "    mapping = defaultdict(dict)\n",
    "    num_user_busi = 0\n",
    "    for user in reviews_u_b:\n",
    "        for buss in reviews_u_b[user]:\n",
    "            num_user_busi += 1\n",
    "            \n",
    "    topic_word = model.topic_word_\n",
    "    num_topics = topic_word.shape[0]\n",
    "    vocab_size = topic_word.shape[1]\n",
    "    \n",
    "    avg_user_to_vvector = getAvgVVector(user_to_vvector, num_topics)\n",
    "    avg_bussiness_to_vvector = getAvgVVector(bussiness_to_vvector, num_topics)\n",
    "    \n",
    "    num_feats = num_topics + 3\n",
    "    X = np.zeros((num_user_busi,num_feats)) #  features from LDA + user_avg + item_avg + 1 offset\n",
    "    Y = np.zeros((num_user_busi,1)) # Ratings - labels\n",
    "    \n",
    "    index = 0\n",
    "    for user in reviews_u_b:\n",
    "        user_topic_dist = getTopicDist(avg_user_to_vvector,model)\n",
    "        if user in user_to_vvector:\n",
    "            user_topic_dist = getTopicDist(user_to_vvector[user],model)\n",
    "        else:\n",
    "            print \"not present in training user:\",user\n",
    "        for buss in reviews_u_b[user]:\n",
    "            buss_topic_dist = getTopicDist(avg_bussiness_to_vvector,model)\n",
    "            if buss in bussiness_to_vvector:\n",
    "                buss_topic_dist = getTopicDist(bussiness_to_vvector[buss],model)\n",
    "            else:\n",
    "                print \"not present in training business:\",buss\n",
    "            lda_feat = np.array([0.0]*num_feats)\n",
    "            for i in range(num_topics):\n",
    "#                 print \"i:\",i\n",
    "                lda_feat[i] = user_topic_dist[0][i] * buss_topic_dist[0][i]\n",
    "            if user in user_to_avg_rating:\n",
    "                lda_feat[num_topics] = user_to_avg_rating[user] \n",
    "            else:\n",
    "                lda_feat[num_topics] = global_avg \n",
    "            if buss in business_to_avg_rating:\n",
    "                lda_feat[num_topics+1] = business_to_avg_rating[buss]\n",
    "            else:\n",
    "                lda_feat[num_topics+1] = global_avg\n",
    "            lda_feat[num_topics + 2] = 1\n",
    "            X[index] = lda_feat\n",
    "            Y[index] = ratings_u_b[user][buss]\n",
    "            if Y[index] == 0:\n",
    "                print \"Y is 0\"\n",
    "            mapping[user][buss] = index\n",
    "            index += 1\n",
    "    return [X,Y,mapping]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printParams(theta,residuals,rank,s):\n",
    "    print \"theta:\",theta,\"residuals:\",residuals,\"rank:\",rank,\"s:\",s\n",
    "\n",
    "global_avg = getGlobalAvg(reviews_u_b_subset, ratings_u_b)\n",
    "print \"baseline mse:\",getBaselineMSE(ratings_u_b,global_avg)\n",
    "\n",
    "print \"build sparse train features\"\n",
    "X_sparse_train,Y_sparse_train,mapping_sparse_train,user_to_vvector,bussiness_to_vvector = buildRegressionFeatures(lda_model,ratings_u_b,\n",
    "                            user_to_avg_rating,business_to_avg_rating,reviews_u_b_sparse_train,\n",
    "                            reviews_b_u_sparse_train,global_avg,vocab)\n",
    "\n",
    "print \"build sparse val features\"\n",
    "# X_sparse_val,Y_sparse_val,mapping_sparse_val = buildRegressionFeatures(lda_model,ratings_u_b,\n",
    "#                             user_to_avg_rating,business_to_avg_rating,reviews_u_b_sparse_val,\n",
    "#                             reviews_b_u_sparse_val,global_avg,vocab)\n",
    "\n",
    "\n",
    "X_sparse_val,Y_sparse_val,mapping_sparse_val = build_test_reg_features(lda_model,user_to_vvector,bussiness_to_vvector,\n",
    "            reviews_u_b_sparse_val,ratings_u_b,global_avg)\n",
    "\n",
    "print \"build sparse test features\"\n",
    "# X_sparse_test,Y_sparse_test,mapping_sparse_test = buildRegressionFeatures(lda_model,ratings_u_b,\n",
    "#                             user_to_avg_rating,business_to_avg_rating,reviews_u_b_sparse_test,\n",
    "#                             reviews_b_u_sparse_test,global_avg,vocab)\n",
    "X_sparse_test,Y_sparse_test,mapping_sparse_test = build_test_reg_features(lda_model,user_to_vvector,bussiness_to_vvector,\n",
    "            reviews_u_b_sparse_test,ratings_u_b,global_avg)\n",
    "\n",
    "# print \"build dense train features\"\n",
    "# X_dense_train,Y_dense_train,mapping_dense_train = buildRegressionFeatures(lda_model,ratings_u_b,\n",
    "#                             user_to_avg_rating,business_to_avg_rating,reviews_u_b_dense_train,\n",
    "#                             reviews_b_u_dense_train,global_avg,vocab)\n",
    "\n",
    "# print \"build dense val features\"\n",
    "# X_dense_val,Y_dense_val,mapping_dense_val = buildRegressionFeatures(lda_model,ratings_u_b,\n",
    "#                             user_to_avg_rating,business_to_avg_rating,reviews_u_b_dense_val,\n",
    "#                             reviews_b_u_dense_val,global_avg,vocab)\n",
    "\n",
    "# print \"build dense test features\"\n",
    "# X_dense_test,Y_dense_test,mapping_dense_test = buildRegressionFeatures(lda_model,ratings_u_b,\n",
    "#                             user_to_avg_rating,business_to_avg_rating,reviews_u_b_dense_test,\n",
    "#                             reviews_b_u_dense_test,global_avg,vocab)\n",
    "\n",
    "# pickle.dump(X, open('X_sparse_train.p','wb'))\n",
    "# pickle.dump(Y, open('Y_sparse_train.p','wb'))\n",
    "# pickle.dump(mapping, open('mapping_sparse_train.p','wb'))\n",
    "\n",
    "# X = pickle.load( open( \"X_sparse_train.p\", \"rb\" ) )\n",
    "# Y = pickle.load( open( \"Y_sparse_train.p\", \"rb\" ) )\n",
    "\n",
    "# print X[1]\n",
    "# # print Y.shape\n",
    "\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X_sparse_train, Y_sparse_train.flatten())\n",
    "# printParams(theta,residuals,rank,s)\n",
    "print \"reg sparse train mse:\", residuals * 1.0 / X_sparse_train.shape[0]\n",
    "print \"reg sparse val mse:\",getMSE(X_sparse_val,Y_sparse_val.flatten(),theta)\n",
    "print \"reg sparse test mse:\",getMSE(X_sparse_test,Y_sparse_test.flatten(),theta)\n",
    "\n",
    "# theta,residuals,rank,s = np.linalg.lstsq(X_dense_train, Y_dense_train.flatten())\n",
    "# # printParams(theta,residuals,rank,s)\n",
    "# print \"reg dense train mse:\", residuals * 1.0 / X_dense_train.shape[0]\n",
    "# print \"reg dense val mse:\",getMSE(X_dense_val,Y_dense_val.flatten(),theta)\n",
    "# print \"reg dense test mse:\",getMSE(X_dense_test,Y_dense_test.flatten(),theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "# vocab = getVocab(reviews_u_b,VOCAB_SIZE)\n",
    "# pickle.dump(vocab, open('vocab.p','wb'))\n",
    "# load the pickles \n",
    "reviews_b_u = pickle.load( open( \"reviews_b_u.p\", \"rb\" ) )\n",
    "reviews_u_b = pickle.load( open( \"reviews_u_b.p\", \"rb\" ) )\n",
    "reviews_b_u_subset = pickle.load( open( \"reviews_b_u_subset.p\", \"rb\" ) )\n",
    "reviews_u_b_subset = pickle.load( open( \"reviews_u_b_subset.p\", \"rb\" ) )\n",
    "vocab = pickle.load( open( \"vocab.p\", \"rb\" ) )\n",
    "user_to_avg_rating = pickle.load( open( \"user_to_avg_rating.p\", \"rb\" ) )\n",
    "business_to_avg_rating = pickle.load( open( \"business_to_avg_rating.p\", \"rb\" ) )\n",
    "ratings_u_b = pickle.load( open( \"ratings_u_b.p\", \"rb\" ) )\n",
    "ratings_b_u = pickle.load( open( \"ratings_b_u.p\", \"rb\" ) )\n",
    "lda_model = pickle.load( open( \"lda_model.p\", \"rb\" ) )\n",
    "\n",
    "reviews_b_u_dense_test = pickle.load( open( \"reviews_b_u_dense_test.p\", \"rb\" ) )\n",
    "reviews_b_u_dense_train = pickle.load( open( \"reviews_b_u_dense_train.p\", \"rb\" ) )\n",
    "reviews_b_u_dense_val = pickle.load( open( \"reviews_b_u_dense_val.p\", \"rb\" ) )\n",
    "\n",
    "reviews_u_b_dense_test = pickle.load( open( \"reviews_u_b_dense_test.p\", \"rb\" ) )\n",
    "reviews_u_b_dense_train = pickle.load( open( \"reviews_u_b_dense_train.p\", \"rb\" ) )\n",
    "reviews_u_b_dense_val = pickle.load( open( \"reviews_u_b_dense_val.p\", \"rb\" ) )\n",
    "\n",
    "reviews_b_u_sparse_test = pickle.load( open( \"reviews_b_u_sparse_test.p\", \"rb\" ) )\n",
    "reviews_b_u_sparse_train = pickle.load( open( \"reviews_b_u_sparse_train.p\", \"rb\" ) )\n",
    "reviews_b_u_sparse_val = pickle.load( open( \"reviews_b_u_sparse_val.p\", \"rb\" ) )\n",
    "\n",
    "reviews_u_b_sparse_test = pickle.load( open( \"reviews_u_b_sparse_test.p\", \"rb\" ) )\n",
    "reviews_u_b_sparse_train = pickle.load( open( \"reviews_u_b_sparse_train.p\", \"rb\" ) )\n",
    "reviews_u_b_sparse_val = pickle.load( open( \"reviews_u_b_sparse_val.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bussiness_to_vvector = getBusineesToVocabVector(reviews_b_u_subset,vocab)\n",
    "# lda_model = trainLDA(reviews_b_u_subset,vocab,50,bussiness_to_vvector)\n",
    "\n",
    "bussiness_to_vvector = getBusineesToVocabVector(reviews_b_u_sparse_train,vocab)\n",
    "print \"bussiness_to_vvector\"\n",
    "print bussiness_to_vvector\n",
    "# lda_model = trainLDA(reviews_b_u_sparse_train,vocab,50,bussiness_to_vvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: good like place really im time one great go back get would ordered little food ive well dont got also\n",
      "Topic 1: food service us table came server minutes waitress back time asked got never one restaurant get said even didnt took\n",
      "Topic 2: delicious great amazing love place fresh best try ever also made sweet little back time atmosphere way favorite ive perfect\n",
      "Topic 3: pizza crust cheese good sauce pizzas wings thin slice toppings garlic salad slices style sausage pie great chicago love ordered\n",
      "Topic 4: place back like food old little counter years would see home first time try one said really going looked dont\n",
      "Topic 5: sandwich sandwiches bread cheese turkey lunch good fresh meat get beef shop chips eat tomato italian quality one try location\n",
      "Topic 6: tea coffee service iced drinks drink good place order ice green really cup hot sweet station also taste like friends\n",
      "Topic 7: wait get food place table order people long waiting time line minutes busy go always love take tables one eat\n",
      "Topic 8: breakfast eggs food good pancakes coffee bacon diner toast egg morning french potatoes place hash menu service sausage great cheese\n",
      "Topic 9: hot charlotte dog chicago fries good beef cheese onion chili line order place italian great sausage get grilled onions long\n",
      "Topic 10: wine cheese great selection brunch bottle french glass duck happy list salad place date hour salmon plate bread go love\n",
      "Topic 11: thai curry pad food spicy chicken soup dish rice lunch noodles dishes fried tofu beef shrimp ordered hot green salad\n",
      "Topic 12: happy hour menu bar great good drinks food chicken dip drink night server service location appetizers really appetizer always ordered\n",
      "Topic 13: pho rolls broth place spring noodles soup good bowl beef egg long service restaurant food noodle pork night rice fast\n",
      "Topic 14: korean tofu soup meat bbq dishes spicy pork noodles beef side eat place really noodle service salad grill belly rice\n",
      "Topic 15: order delivery ordered minutes time said called told customer got call phone service back asked would even ordering hour manager\n",
      "Topic 16: location always service staff friendly food love time good fast clean order get great one fresh chipotle every line manager\n",
      "Topic 17: pita greek hummus food chicken salad fries meat fresh lamb bread grilled side plate sauce tomato meal always salads dressing\n",
      "Topic 18: lunch place downtown work great quick special street good spot little area pretty around menu get prices service parking right\n",
      "Topic 19: bar place night good drinks great food fun music drink beer atmosphere friends people pretty back cool nice tables bartender\n",
      "Topic 20: pittsburgh best ive one also get definitely city im every would ever many street huge dont nice much around though\n",
      "Topic 21: place owner great friendly food family best nice small back owners us little try definitely fresh staff reviews service delicious\n",
      "Topic 22: food fast drive order location always service get taco fries one time chicken late quick night clean never staff eat\n",
      "Topic 23: like get one dont go im even time would ive never know place want people much two going 2 think\n",
      "Topic 24: best place get beef meat delicious order everything huge taste make ever style home love great ive also hot town\n",
      "Topic 25: cream cheese ice chocolate go dessert also salad really time great get good pot first went every one 2 experience\n",
      "Topic 26: bbq ribs sauce pork good meat pulled brisket sides beans sandwich honey sweet potato salad dry beef side flavor tender\n",
      "Topic 27: dinner dessert us course special meal great nice night lobster experience amazing chocolate service restaurant cake well reservation table would\n",
      "Topic 28: pie cafe room hotel casino nice stay clean good night free got would station cheap restaurant great really strip floor\n",
      "Topic 29: salad soup chicken lunch bar sweet salads fresh good potato pasta bread tomatoes dressing eat meal always menu baked items\n",
      "Topic 30: phoenix place best valley scottsdale go one every location love im years many new happy amazing green get friend take\n",
      "Topic 31: chicken food rice sauce bowl good meat meal spicy place order get lunch love plate white portions veggies fast beef\n",
      "Topic 32: mexican food salsa chips tacos burrito beans good taco cheese rice carne green asada sauce beef chicken fresh authentic guacamole\n",
      "Topic 33: sushi roll rolls fresh fish tuna japanese place spicy sashimi salmon rice chef bar quality chefs happy hour eat salad\n",
      "Topic 34: food place good like really better would bad service pretty go price restaurant dont decent much eat ok prices nothing\n",
      "Topic 35: fish shrimp seafood lobster crab good fried sauce fresh oysters chips house green red restaurant garlic legs rice ordered get\n",
      "Topic 36: steak salad rib prime steaks good cooked medium filet potatoes potato dinner great meat rare ordered meal bread baked well\n",
      "Topic 37: kids red family time place great food love free like birthday go fun one experience location get mall eat take\n",
      "Topic 38: buffet food indian lunch chicken dishes buffets dinner fresh eat good curry lamb garlic selection also spicy hot try everything\n",
      "Topic 39: burger fries burgers cheese good food onion sandwich ordered bacon french bun order grilled chili meat great got cooked greasy\n",
      "Topic 40: beer wings food good bar game beers sports great place service watch selection hot chicken sauce fries cheese nachos specials\n",
      "Topic 41: chicken fried food good cheese mac potatoes gravy mashed corn meal dinner sweet bread plate sides pork beans green pie\n",
      "Topic 42: chinese food chicken fried soup rice egg beef good pork shrimp dishes sauce sour hot lunch restaurant dish noodles place\n",
      "Topic 43: like also place always great selection options love ive im vegetarian go vegan get really dont want good many find\n",
      "Topic 44: vegas place las strip service time come us like one came night definitely good late pretty town go love best\n",
      "Topic 45: food restaurant service menu good dish ordered meal sauce like dishes restaurants one served dinner us experience came would table\n",
      "Topic 46: italian pasta bread sauce food salad chicken olive good wine dish cheese meal restaurant dinner fresh oil sausage garlic dishes\n",
      "Topic 47: japanese ramen honey food toast good beef menu fried dishes place rice chicken items try pork authentic bowl grilled wall\n",
      "Topic 48: great good place service food always love best friendly lunch delicious favorite ive time staff go really amazing years prices\n",
      "Topic 49: patio great food outside view nice place would outdoor seating atmosphere enjoy beautiful inside sit little area live back enjoyed\n"
     ]
    }
   ],
   "source": [
    "# avg_vec = getAvgVVector(bussiness_to_vvector, 50)\n",
    "# print \"avg_vec:\",avg_vec\n",
    "# pickle.dump(lda_model, open('lda_model_sparse.p','wb'))\n",
    "printTopWordsPerTopic(20,lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bussiness_to_vvector = getBusineesToVocabVector(reviews_b_u_subset,vocab)\n",
    "print bussiness_to_vvector['pOaM7FkXM8lEQmqA32gqUw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_to_vvector = getUserToVocabVector(reviews_u_b_subset,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bussiness_to_vvector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-72d3dc82ad4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print bussiness_to_vvector['pOaM7FkXM8lEQmqA32gqUw']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgetTopTopics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbussiness_to_vvector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pOaM7FkXM8lEQmqA32gqUw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print getTopicDist(bussiness_to_vvector['pOaM7FkXM8lEQmqA32gqUw'],lda_model)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print user_to_vvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print len(reviews_b_u)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bussiness_to_vvector' is not defined"
     ]
    }
   ],
   "source": [
    "# print bussiness_to_vvector['pOaM7FkXM8lEQmqA32gqUw']\n",
    "# getTopTopics(bussiness_to_vvector['pOaM7FkXM8lEQmqA32gqUw'],lda_model,num_top=3)\n",
    "# print getTopicDist(bussiness_to_vvector['pOaM7FkXM8lEQmqA32gqUw'],lda_model)[0]\n",
    "# print user_to_vvector\n",
    "# print len(reviews_b_u)\n",
    "# print len(reviews_u_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
