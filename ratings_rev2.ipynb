{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "userItemRating = {}\n",
    "itemUserRating = {}\n",
    "count = 0\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if count >= 600000:\n",
    "        break\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "    if item not in itemUserRating:\n",
    "        itemUserRating[item] = {}\n",
    "    itemUserRating[item][user] = l['rating']\n",
    "    if user not in userItemRating:\n",
    "        userItemRating[user] = {}\n",
    "    userItemRating[user][item] = l['rating']\n",
    "    count += 1\n",
    "   \n",
    "  \n",
    "# pickle.dump(userItemRating, open( \"userItemRating.p\", \"wb\" ) )\n",
    "# pickle.dump(itemUserRating, open( \"itemUserRating.p\", \"wb\" ) )\n",
    "# pickle.dump(userRatings, open( \"userRatings.p\", \"wb\" ) )\n",
    "# pickle.dump(allRatings, open( \"allRatings.p\", \"wb\" ) )\n",
    "\n",
    "pickle.dump(userItemRating, open( \"userItemRating_600k.p\", \"wb\" ) )\n",
    "pickle.dump(itemUserRating, open( \"itemUserRating_600k.p\", \"wb\" ) )\n",
    "\n",
    "\n",
    "# globalAverage = sum(allRatings) / len(allRatings)\n",
    "# userAverage = {}\n",
    "# for u in userRatings:\n",
    "#     userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "\n",
    "# predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "# for l in open(\"pairs_Rating.txt\"):\n",
    "#   if l.startswith(\"userID\"):\n",
    "#     #header\n",
    "#     predictions.write(l)\n",
    "#     continue\n",
    "#   u,i = l.strip().split('-')\n",
    "#   if u in userAverage:\n",
    "#     predictions.write(u + '-' + i + ',' + str(userAverage[u]) + '\\n')\n",
    "#   else:\n",
    "#     predictions.write(u + '-' + i + ',' + str(globalAverage) + '\\n')\n",
    "\n",
    "# predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "userItemRating = pickle.load( open( \"userItemRating.p\", \"rb\" ) )\n",
    "itemUserRating = pickle.load( open( \"itemUserRating.p\", \"rb\" ) )\n",
    "userItemRating_100k = pickle.load( open( \"userItemRating_100k.p\", \"rb\" ) )\n",
    "itemUserRating_100k = pickle.load( open( \"itemUserRating_100k.p\", \"rb\" ) )\n",
    "userItemRating_900k = pickle.load( open( \"userItemRating_900k.p\", \"rb\" ) )\n",
    "itemUserRating_900k = pickle.load( open( \"itemUserRating_900k.p\", \"rb\" ) )\n",
    "userItemRating_600k = pickle.load( open( \"userItemRating_600k.p\", \"rb\" ) )\n",
    "itemUserRating_600k = pickle.load( open( \"itemUserRating_600k.p\", \"rb\" ) )\n",
    "\n",
    "# print userItemRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "#load pickles \n",
    "# userItemRating = pickle.load( open( \"userItemRating.p\", \"rb\" ) )\n",
    "# itemUserRating = pickle.load( open( \"itemUserRating.p\", \"rb\" ) )\n",
    "# subsetSize = 1000\n",
    "# subsetCount = 0\n",
    "\n",
    "# userItemRatingSubset = {}\n",
    "# for user in userItemRating:\n",
    "#     subsetCount += 1\n",
    "#     if subsetCount == subsetSize:\n",
    "#         break\n",
    "#     for item in userItemRating[user]:\n",
    "#         if user not in userItemRatingSubset:\n",
    "#             userItemRatingSubset[user] = {}\n",
    "#         userItemRatingSubset[user][item] = userItemRating[user][item]\n",
    "        \n",
    "        \n",
    "# userItemRating = userItemRatingSubset\n",
    "            \n",
    "#objective\n",
    "def f(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K):\n",
    "    obj = 0.0\n",
    "    count = 0.0\n",
    "    for user in userItemRating:\n",
    "        for item in userItemRating[user]:\n",
    "            if len(gamma_u[user]) != len(gamma_i[item]):\n",
    "                print \"len gamma u:\",len(gamma_u[user])\n",
    "                print \"len gamma i:\",len(gamma_i[item])\n",
    "                print \"type gamma u:\",type(gamma_u[user])\n",
    "                print \"type gamma i:\",type(gamma_i[item])\n",
    "            obj += np.power((alpha + beta_u[user] + beta_i[item] + np.dot(gamma_u[user],gamma_i[item]) \n",
    "                             - userItemRating[user][item]),2)\n",
    "            count += 1\n",
    "#     print \"obj type:\",type(obj)\n",
    "    # regularization terms\n",
    "    for user in beta_u:\n",
    "        obj += lam * math.pow((beta_u[user]),2)\n",
    "        obj += lam * sum(np.power((gamma_u[user]),2))\n",
    "#         obj += lam * np.dot(gamma_u[user],gamma_u[user])\n",
    "    \n",
    "    for item in beta_i:\n",
    "        obj += lam * math.pow((beta_i[item]),2)\n",
    "#         obj += lam * sum(np.power((gamma_i[item]),2))\n",
    "        obj += lam * np.dot(gamma_i[item],gamma_i[item])\n",
    "#     print \"obj:\" , obj\n",
    "#     print \"count;\",count \n",
    "    return np.float(obj)/count\n",
    "#     return float(obj)\n",
    "\n",
    "def grad_alpha(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K):\n",
    "    grad = 0.0\n",
    "    count = 0.0\n",
    "    for user in userItemRating:\n",
    "        for item in userItemRating[user]:\n",
    "            grad += 2 * (alpha + beta_u[user] + beta_i[item] + np.dot(gamma_i[item],gamma_u[user]) \n",
    "                         - userItemRating[user][item])\n",
    "            count += 1.0\n",
    "    return float(grad)/float(count)\n",
    "\n",
    "def grad_beta_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K):\n",
    "    grad = {}\n",
    "    for user in userItemRating:\n",
    "        grad[user] = 0\n",
    "        count = 0.0\n",
    "        for item in userItemRating[user]:\n",
    "            grad[user] += 2 * (alpha + beta_u[user] + beta_i[item] + np.dot(gamma_i[item],gamma_u[user]) \n",
    "                         - userItemRating[user][item])\n",
    "            count += 1.0\n",
    "        grad[user] += 2 * lam * beta_u[user]\n",
    "        grad[user] /= float(count)\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def grad_beta_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K):\n",
    "    grad = {}\n",
    "    for item in itemUserRating:\n",
    "        grad[item] = 0\n",
    "        count = 0.0\n",
    "        for user in itemUserRating[item]:\n",
    "            grad[item] += 2 * (alpha + beta_u[user] + beta_i[item] + np.dot(gamma_i[item],gamma_u[user]) \n",
    "                         - itemUserRating[item][user])\n",
    "            count += 1.0\n",
    "        grad[item] += 2 * lam * beta_i[item]\n",
    "        grad[item] /= float(count)\n",
    "    return grad\n",
    "\n",
    "def grad_gamma_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K):\n",
    "    grad = {}\n",
    "    for user in userItemRating:\n",
    "        grad[user] = np.array([0.0]*K)\n",
    "        count = 0.0\n",
    "        for item in userItemRating[user]:\n",
    "            grad[user] = grad[user] + 2 * (alpha + beta_u[user] + beta_i[item] + np.dot(gamma_i[item],gamma_u[user]) \n",
    "                                           - userItemRating[user][item]) * gamma_i[item]\n",
    "            count += 1.0\n",
    "        grad[user] = grad[user] + 2 * lam * gamma_u[user]\n",
    "        grad[user] /= float(count)\n",
    "    return grad\n",
    "\n",
    "\n",
    "def grad_gamma_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K):\n",
    "    grad = {}\n",
    "#     for item in gamma_i:\n",
    "#         grad[item] = np.array([0]*K)\n",
    "#     for user in userItemRating:\n",
    "#         for item in userItemRating[user]:\n",
    "#             grad[item] += 2 * (alpha + beta_u[user] + beta_i[item] + np.dot(gamma_i[item],gamma_u[user]) \n",
    "#                          - userItemRating[user][item]) * gamma_u[user]\n",
    "#     for item in gamma_i:\n",
    "#         grad[item] += 2 * lam * gamma_i[item]\n",
    "    for item in itemUserRating:\n",
    "        grad[item] = np.array([0.0]*K)\n",
    "        count = 0.0\n",
    "        for user in itemUserRating[item]:\n",
    "            grad[item] += 2 * (alpha + beta_u[user] + beta_i[item] + np.dot(gamma_i[item],gamma_u[user]) \n",
    "                         - userItemRating[user][item]) * gamma_u[user]\n",
    "            count += 1.0\n",
    "        grad[item] += 2 * lam * gamma_i[item]\n",
    "        grad[item] /= float(count)\n",
    "    return grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_alpha(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i):\n",
    "    grad = 0.0\n",
    "    user_item_count = 0.0\n",
    "    for user in userItemRating:\n",
    "        for item in userItemRating[user]:\n",
    "            grad += ( userItemRating[user][item] - (beta_u[user] + beta_i[item] + np.dot(gamma_i[item],gamma_u[user])))\n",
    "            user_item_count += 1\n",
    "    return float(grad)/float(user_item_count)\n",
    "\n",
    "def update_beta_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i):\n",
    "    grad = {}\n",
    "    for user in userItemRating:\n",
    "        grad[user] = 0.0\n",
    "        item_count = 0.0\n",
    "        for item in userItemRating[user]:\n",
    "            grad[user] += (userItemRating[user][item] - (alpha + beta_i[item] + np.dot(gamma_i[item],gamma_u[user])))\n",
    "            item_count += 1\n",
    "        grad[user] = float(grad[user]) / float(lam + item_count)\n",
    "    return grad\n",
    "\n",
    "def update_beta_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i):\n",
    "    grad = {}\n",
    "    for item in itemUserRating:\n",
    "        grad[item] = 0\n",
    "        count = 0.0\n",
    "        for user in itemUserRating[item]:\n",
    "            grad[item] +=  (itemUserRating[item][user] - (alpha + beta_u[user] + np.dot(gamma_i[item],gamma_u[user])))\n",
    "            count += 1.0\n",
    "        grad[item] = float(grad[item]) / float(lam + count)\n",
    "    return grad\n",
    "\n",
    "def update_gamma_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K):\n",
    "    grad = {}\n",
    "    for user in userItemRating:\n",
    "        grad[user] = np.array([0.0]*K)\n",
    "        first_term = 0.0\n",
    "        second_term = 0.0\n",
    "        for item in userItemRating[user]:\n",
    "            first_term += (gamma_i[item].reshape([K,1]) * gamma_i[item].reshape([1,K]) + lam * np.identity(K)) \n",
    "            second_term +=  ( (userItemRating[user][item] \n",
    "                              - (alpha + beta_i[item] + beta_u[user]))* gamma_i[item].reshape([K,1]) )\n",
    "        result = np.dot(np.linalg.inv(first_term), second_term).flatten()\n",
    "#         print \"first:\",np.linalg.inv(first_term).shape\n",
    "#         print \"second:\",second_term.shape\n",
    "#         print \"result:\",result.shape\n",
    "        grad[user] = result\n",
    "    return grad\n",
    "\n",
    "def update_gamma_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K):\n",
    "    grad = {}\n",
    "    for item in itemUserRating:\n",
    "#         grad[item] = np.array([0.0]*K)\n",
    "        grad[item] = np.array([0.0]*K)\n",
    "        first_term = 0.0\n",
    "        second_term = 0.0\n",
    "        for user in itemUserRating[item]:\n",
    "            first_term += gamma_u[user].reshape([K,1]) * gamma_u[user].reshape([1,K]) + lam * np.identity(K)\n",
    "            second_term += (itemUserRating[item][user] - (alpha + beta_i[item] + beta_u[user]))* gamma_u[user].reshape([K,1]) \n",
    "        result = np.dot(np.linalg.inv(first_term), second_term).flatten()\n",
    "#         print result.shape\n",
    "        grad[item] = result\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_with_gamma_u(itemUserRating,userItemRating,lam\n",
    "                       ,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss):\n",
    "    iter = 0\n",
    "    while (iter < 1000):\n",
    "        iter += 1\n",
    "        obj = f(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        loss.append(obj)\n",
    "        alpha = update_alpha(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "        beta_u = update_beta_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "        beta_i = update_beta_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "        gamma_u = update_gamma_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "#         gradient_gamma_i = grad_gamma_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "\n",
    "        if iter % 1 == 0:\n",
    "            print \"update_with_gamma_u iter :\", iter , \" loss:\",obj\n",
    "        if len(loss) > 2 and abs(loss[len(loss)-1] - loss[len(loss)-2]) < ACCURACY:\n",
    "            print \"update_with_gamma_u converged iter :\", iter , \" loss:\",obj\n",
    "            break\n",
    "    return [alpha,beta_u,beta_i,gamma_u,gamma_i,loss]\n",
    "\n",
    "def update_with_gamma_i(itemUserRating,userItemRating,lam,\n",
    "                       alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss):\n",
    "    iter = 0\n",
    "    while (iter < 1000):\n",
    "        iter += 1\n",
    "        obj = f(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        loss.append(obj)\n",
    "        alpha = update_alpha(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "        beta_u = update_beta_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "        beta_i = update_beta_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "#         gamma_u = update_gamma_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        gamma_i = update_gamma_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "\n",
    "        if iter % 1 == 0:\n",
    "            print \"update_with_gamma_i iter :\", iter , \" loss:\",obj\n",
    "        if len(loss) > 2 and abs(loss[len(loss)-1] - loss[len(loss)-2]) < ACCURACY:\n",
    "            print \"update_with_gamma_i converged iter :\", iter , \" loss:\",obj\n",
    "            break    \n",
    "    return [alpha,beta_u,beta_i,gamma_u,gamma_i,loss]\n",
    "    \n",
    "def train_iterative(itemUserRating,userItemRating,lam,\n",
    "                       alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,superloss):\n",
    "    iter = 0\n",
    "    while (iter < 1000):\n",
    "        iter += 1\n",
    "        loss = []\n",
    "        alpha,beta_u,beta_i,gamma_u,gamma_i,loss = update_with_gamma_u(itemUserRating,userItemRating,lam\n",
    "                       ,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss)\n",
    "        superloss.append(loss[len(loss) - 1])\n",
    "        loss = []\n",
    "        alpha,beta_u,beta_i,gamma_u,gamma_i,loss = update_with_gamma_i(itemUserRating,userItemRating,lam,\n",
    "                       alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss)\n",
    "        superloss.append(loss[len(loss) - 1])\n",
    "        if len(superloss) > 2 and abs(superloss[len(superloss)-1] - superloss[len(superloss)-2]) < ACCURACY:\n",
    "            print \"training converged at super iter :\", iter , \" superloss:\",superloss[len(superloss)-1]\n",
    "            break\n",
    "    return [alpha,beta_u,beta_i,gamma_u,gamma_i,loss]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "# gradient_alpha = grad_alpha(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "# gradient_beta_u = grad_beta_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,user)\n",
    "# gradient_beta_i = grad_beta_i(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,user)\n",
    "# gradient_gamma_u = grad_gamma_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,user)\n",
    "# gradient_gamma_i = grad_gamma_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,user)\n",
    "\n",
    "def train_with_gamma_u(itemUserRating,userItemRating,lam\n",
    "                       ,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,lr):\n",
    "    iter = 0\n",
    "    while (iter < 1000):\n",
    "        iter += 1\n",
    "        obj = f(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        loss.append(obj)\n",
    "        gradient_alpha = grad_alpha(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        gradient_beta_u = grad_beta_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        gradient_beta_i = grad_beta_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        gradient_gamma_u = grad_gamma_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "#         gradient_gamma_i = grad_gamma_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "\n",
    "        if iter % 1 == 0:\n",
    "            print \"train_with_gamma_u iter :\", iter , \" loss:\",obj\n",
    "        if len(loss) > 2 and abs(loss[len(loss)-1] - loss[len(loss)-2]) < ACCURACY:\n",
    "            print \"train_with_gamma_u converged iter :\", iter , \" loss:\",obj\n",
    "            break\n",
    "        \n",
    "        alpha -= lr * gradient_alpha\n",
    "        for user in gamma_u:\n",
    "            beta_u[user] -= lr * gradient_beta_u[user]\n",
    "            gamma_u[user] -= lr * gradient_gamma_u[user]\n",
    "\n",
    "        for item in gamma_i:\n",
    "            beta_i[item] -= lr * gradient_beta_i[item]\n",
    "#             gamma_i[item] -= lr * gradient_gamma_i[item]\n",
    "    return [alpha,beta_u,beta_i,gamma_u,gamma_i,loss]\n",
    "\n",
    "def train_with_gamma_i(itemUserRating,userItemRating,lam,\n",
    "                       alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,lr):\n",
    "    iter = 0\n",
    "    while (iter < 1000):\n",
    "        iter += 1\n",
    "        obj = f(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        loss.append(obj)\n",
    "        gradient_alpha = grad_alpha(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        gradient_beta_u = grad_beta_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        gradient_beta_i = grad_beta_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "#         gradient_gamma_u = grad_gamma_u(userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "        gradient_gamma_i = grad_gamma_i(itemUserRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K)\n",
    "\n",
    "        if iter % 1 == 0:\n",
    "            print \"train_with_gamma_i iter :\", iter , \" loss:\",obj\n",
    "        if len(loss) > 2 and abs(loss[len(loss)-1] - loss[len(loss)-2]) < ACCURACY:\n",
    "            print \"train_with_gamma_i converged iter :\", iter , \" loss:\",obj\n",
    "            break\n",
    "        \n",
    "        \n",
    "            \n",
    "        alpha -= lr * gradient_alpha\n",
    "        for user in gamma_u:\n",
    "            beta_u[user] -= lr * gradient_beta_u[user]\n",
    "#             gamma_u[user] -= lr * gradient_gamma_u[user]\n",
    "\n",
    "        for item in gamma_i:\n",
    "            beta_i[item] -= lr * gradient_beta_i[item]\n",
    "            gamma_i[item] -= lr * gradient_gamma_i[item]\n",
    "    return [alpha,beta_u,beta_i,gamma_u,gamma_i,loss]\n",
    "\n",
    "def train(itemUserRating,userItemRating,lam,\n",
    "                       alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,lr,superloss):\n",
    "    iter = 0\n",
    "    while (iter < 1000):\n",
    "        iter += 1\n",
    "        [alpha,beta_u,beta_i,gamma_u,gamma_i,loss] = train_with_gamma_u(itemUserRating,userItemRating,lam\n",
    "                       ,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,lr)\n",
    "        superloss.append(loss[len(loss) - 1])\n",
    "        \n",
    "        [alpha,beta_u,beta_i,gamma_u,gamma_i,loss] = train_with_gamma_i(itemUserRating,userItemRating,lam,\n",
    "                       alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,lr)\n",
    "        superloss.append(loss[len(loss) - 1])\n",
    "        \n",
    "        if len(superloss) > 2 and abs(superloss[len(superloss)-1] - superloss[len(superloss)-2]) < ACCURACY:\n",
    "            print \"training converged at super iter :\", iter , \" superloss:\",superloss[len(superloss)-1]\n",
    "            return superloss[len(superloss)-1]\n",
    "\n",
    "def write_Lambda_K_Variations(list):\n",
    "    predictions = open(\"lambda_k_variations.txt\", 'w')\n",
    "    for l in list:\n",
    "        predictions.write(l)\n",
    "    predictions.close()\n",
    "    \n",
    "def write_predictions_Rating(alpha,beta_u,beta_i,gamma_u,gamma_i):\n",
    "    predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "    for l in open(\"pairs_Rating.txt\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            predictions.write(l) #header\n",
    "            continue\n",
    "        u,i = l.strip().split('-')\n",
    "        predictions.write(u + '-' + i + ',' + str(predict_rating(u,i,4.218,alpha,beta_u,beta_i,gamma_u,gamma_i)) + '\\n')\n",
    "    predictions.close()\n",
    "    \n",
    "def predict_rating(user,item,avg,alpha,beta_u,beta_i,gamma_u,gamma_i):\n",
    "    if user in beta_u and item in beta_i:\n",
    "        pred = alpha + beta_u[user]+beta_i[item] + np.dot(gamma_u[user],gamma_i[item])\n",
    "#         print \"pred:\",pred\n",
    "        return pred\n",
    "    else:\n",
    "        return avg\n",
    "    \n",
    "def getMSE(userItemRating,avg,alpha,beta_u,beta_i,gamma_u,gamma_i):\n",
    "    se = 0.0\n",
    "    count = 0\n",
    "    for user in userItemRating:\n",
    "        for item in userItemRating[user]:\n",
    "            pred = predict_rating(user,item,avg,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "            se += math.pow((pred - userItemRating[user][item]),2)\n",
    "            count += 1\n",
    "    return float(se)/float(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lam = 1\n",
    "lambdas = [5]\n",
    "# lambdas = [10]\n",
    "lrs =      [0.05 for i in range(len(lambdas))]\n",
    "Ks = [5]\n",
    "# Ks = [5]\n",
    "alpha = random.random()\n",
    "K = 5        #dimensions of latent factor model\n",
    "beta_u  = {} #scalar value for each user\n",
    "beta_i  = {} #scalar value for each item\n",
    "gamma_u = {} #K dim vector for each user\n",
    "gamma_i = {} #K dim vector for each item\n",
    "# lr = 0.000005\n",
    "lr = 0.1\n",
    "loss = []\n",
    "superloss = []\n",
    "ACCURACY = 0.001\n",
    "\n",
    "#initialize model parameters\n",
    "def initializeModelParams(itemUserRating,userItemRating,beta_i,beta_u,gamma_i,gamma_u,K):\n",
    "    for user in userItemRating:\n",
    "        beta_u[user] = random.random()\n",
    "#         gamma_u[user] = np.matrix(np.array([random.random() for i in range(K)]).reshape([K,1]))\n",
    "        gamma_u[user] = np.array([random.random() for i in range(K)])\n",
    "        for item in userItemRating[user]:\n",
    "            if item not in beta_i:\n",
    "                beta_i[item]= random.random()\n",
    "            if item not in gamma_i:\n",
    "                gamma_i[item]=np.array([random.random() for i in range(K)])\n",
    "    alpha = pickle.load( open( \"alpha.p\", \"rb\" ) )\n",
    "    beta_u = pickle.load( open( \"beta_u.p\", \"rb\" ) )\n",
    "    beta_i = pickle.load( open( \"beta_i.p\", \"rb\" ) )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# out = []\n",
    "# out.append(\"lam\\tK\\ttrain_loss\\ttest_loss\\n\")\n",
    "# avg = 4.19\n",
    "# for i in range(len(lambdas)):\n",
    "#     lam = lambdas[i]\n",
    "#     lr = lrs[i]\n",
    "#     print \"lr:\",lr\n",
    "#     for K in Ks:\n",
    "#         beta_u  = {} #scalar value for each user\n",
    "#         beta_i  = {} #scalar value for each item\n",
    "#         gamma_u = {} #K dim vector for each user\n",
    "#         gamma_i = {} #K dim vector for each item\n",
    "#         alpha = random.random()\n",
    "#         loss = []\n",
    "#         superloss = []\n",
    "#         initializeModelParams(itemUserRating_100k,userItemRating_100k,beta_i,beta_u,gamma_i,gamma_u,K)\n",
    "#         train(itemUserRating_100k,userItemRating_100k,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,lr,superloss)\n",
    "#         train_loss = getMSE(userItemRating_100k,avg,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "#         test_loss = getMSE(userItemRating_900k,avg,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "#         out.append(str(lam) + \"\\t\" + str(K) + \"\\t\" + str(train_loss) + \"\\t\" + str(test_loss) + \"\\n\")\n",
    "#         print \"TRAINING complete WITH K:\", K , \" LAMBDA:\", lam\n",
    "#         write_Lambda_K_Variations(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_with_gamma_u iter : 1  loss: 7.05444203985\n",
      "update_with_gamma_u iter : 2  loss: 2.26510469825\n",
      "update_with_gamma_u iter : 3  loss: 1.09981143879\n",
      "update_with_gamma_u iter : 4  loss: 1.01939677353\n",
      "update_with_gamma_u iter : 5  loss: 1.00390069176\n",
      "update_with_gamma_u iter : 6  loss: 0.9956228165\n",
      "update_with_gamma_u iter : 7  loss: 0.989260370734\n",
      "update_with_gamma_u iter : 8  loss: 0.983951109904\n",
      "update_with_gamma_u iter : 9  loss: 0.979459229031\n",
      "update_with_gamma_u iter : 10  loss: 0.975666105956\n",
      "update_with_gamma_u iter : 11  loss: 0.972480149579\n",
      "update_with_gamma_u iter : 12  loss: 0.969819927161\n",
      "update_with_gamma_u iter : 13  loss: 0.967611397565\n",
      "update_with_gamma_u iter : 14  loss: 0.96578773217\n",
      "update_with_gamma_u iter : 15  loss: 0.964289397903\n",
      "update_with_gamma_u iter : 16  loss: 0.963064060554\n",
      "update_with_gamma_u iter : 17  loss: 0.962066272161\n",
      "update_with_gamma_u converged iter : 17  loss: 0.962066272161\n",
      "update_with_gamma_i iter : 1  loss: 0.961256993496\n",
      "update_with_gamma_i iter : 2  loss: 0.654364944281\n",
      "update_with_gamma_i iter : 3  loss: 0.653187036981\n",
      "update_with_gamma_i iter : 4  loss: 0.6527677132\n",
      "update_with_gamma_i converged iter : 4  loss: 0.6527677132\n",
      "update_with_gamma_u iter : 1  loss: 0.65243215262\n",
      "update_with_gamma_u iter : 2  loss: 0.651936531418\n",
      "update_with_gamma_u iter : 3  loss: 0.651723019389\n",
      "update_with_gamma_u converged iter : 3  loss: 0.651723019389\n",
      "update_with_gamma_i iter : 1  loss: 0.651553419976\n",
      "update_with_gamma_i iter : 2  loss: 0.65141867697\n",
      "update_with_gamma_i iter : 3  loss: 0.651312376524\n",
      "update_with_gamma_i converged iter : 3  loss: 0.651312376524\n",
      "training converged at super iter : 2  superloss: 0.651312376524\n",
      "TRAINING complete WITH K: 5  LAMBDA: 5\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "out.append(\"lam\\tK\\ttrain_loss\\ttest_loss\\n\")\n",
    "avg = 4.19\n",
    "beta_u  = {} #scalar value for each user\n",
    "beta_i  = {} #scalar value for each item\n",
    "gamma_u = {} #K dim vector for each user\n",
    "gamma_i = {} #K dim vector for each item\n",
    "alpha = random.random()\n",
    "for i in range(len(lambdas)):\n",
    "    lam = lambdas[i]\n",
    "    for K in Ks:\n",
    "        beta_u  = {} #scalar value for each user\n",
    "        beta_i  = {} #scalar value for each item\n",
    "        gamma_u = {} #K dim vector for each user\n",
    "        gamma_i = {} #K dim vector for each item\n",
    "        alpha = pickle.load( open( \"alpha.p\", \"rb\" ) )\n",
    "        loss = []\n",
    "        superloss = []\n",
    "#         initializeModelParams(itemUserRating_100k,userItemRating_100k,beta_i,beta_u,gamma_i,gamma_u,K)\n",
    "#         alpha,beta_u,beta_i,gamma_u,gamma_i,loss = train_iterative(itemUserRating_100k,userItemRating_100k,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,superloss)\n",
    "        initializeModelParams(itemUserRating,userItemRating,beta_i,beta_u,gamma_i,gamma_u,K)\n",
    "        alpha,beta_u,beta_i,gamma_u,gamma_i,loss = train_iterative(itemUserRating,userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,superloss)        \n",
    "        train_loss = getMSE(userItemRating_100k,avg,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "        test_loss = getMSE(userItemRating_900k,avg,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "        out.append(str(lam) + \"\\t\" + str(K) + \"\\t\" + str(train_loss) + \"\\t\" + str(test_loss) + \"\\n\")\n",
    "        print \"TRAINING complete WITH K:\", K , \" LAMBDA:\", lam\n",
    "        write_Lambda_K_Variations(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = []\n",
    "superloss = []\n",
    "beta_u  = {} #scalar value for each user\n",
    "beta_i  = {} #scalar value for each item\n",
    "gamma_u = {} #K dim vector for each user\n",
    "gamma_i = {} #K dim vector for each item\n",
    "K = 3\n",
    "lr = 0.005\n",
    "lam = 10\n",
    "alpha = random.random()\n",
    "# initializeModelParams(itemUserRating,userItemRating,beta_i,beta_u,gamma_i,gamma_u,K)\n",
    "# train(itemUserRating,userItemRating,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,lr,superloss)\n",
    "initializeModelParams(itemUserRating_100k,userItemRating_100k,beta_i,beta_u,gamma_i,gamma_u,K)\n",
    "train(itemUserRating_100k,userItemRating_100k,lam,alpha,beta_u,beta_i,gamma_u,gamma_i,K,loss,lr,superloss)\n",
    "train_loss = getMSE(userItemRating_100k,avg,alpha,beta_u,beta_i,gamma_u,gamma_i)\n",
    "test_loss = getMSE(userItemRating_900k,avg,alpha,beta_u,beta_i,gamma_u,gamma_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_predictions_Rating(alpha,beta_u,beta_i,gamma_u,gamma_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.12633356236\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# a = np.matrix(np.ones(4))\n",
    "# a=  np.random.random([3,3])\n",
    "# print a \n",
    "# # b = np.invert(a)\n",
    "\n",
    "# c = np.linalg.inv(np.identity(5))\n",
    "\n",
    "# c * np.identity(5)\n",
    "\n",
    "# print userItemRating[user]\n",
    "user = 'U732551804'\n",
    "item = 'I238406892'\n",
    "print np.power((alpha + beta_u[user] + beta_i[item] + np.dot(gamma_u[user],gamma_i[item]) \n",
    "                             - userItemRating[user][item]),2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
